import streamlit as st
import pandas as pd
import os
import joblib
import numpy as np
from sklearn.base import BaseEstimator, ClassifierMixin
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Nadam
from rdkit.Chem import Descriptors
from rdkit import Chem
from sklearn.preprocessing import QuantileTransformer, StandardScaler
from xgboost import XGBClassifier
import gdown
import requests

class KerasNNWrapper(BaseEstimator, ClassifierMixin):
    def __init__(self, input_dim=None, lr=0.001, epochs=30, batch_size=32, verbose=0,
                 dropout_rate=0.3, l2_lambda=0.001):
        self.input_dim = input_dim
        self.lr = lr
        self.epochs = epochs
        self.batch_size = batch_size
        self.verbose = verbose
        self.dropout_rate = dropout_rate
        self.l2_lambda = l2_lambda
        self.model_ = None

    def _build_model(self):
        model = Sequential()
        model.add(Dense(128, activation="relu", input_dim=self.input_dim,
                        kernel_regularizer=l2(self.l2_lambda)))
        model.add(Dropout(self.dropout_rate))
        model.add(Dense(256, activation="relu", kernel_regularizer=l2(self.l2_lambda)))
        model.add(Dropout(self.dropout_rate))
        model.add(Dense(128, activation="relu", kernel_regularizer=l2(self.l2_lambda)))
        model.add(Dropout(self.dropout_rate))
        model.add(Dense(64, activation="relu", kernel_regularizer=l2(self.l2_lambda)))
        model.add(Dense(1, activation="sigmoid"))
        model.compile(optimizer=Nadam(learning_rate=self.lr),
                      loss="binary_crossentropy",
                      metrics=["accuracy"])
        return model

    def fit(self, X, y):
        self.model_ = self._build_model()
        self.model_.fit(X, y, epochs=self.epochs,
                        batch_size=self.batch_size,
                        verbose=self.verbose)
        return self

    def predict(self, X):
        pred = self.model_.predict(X)
        return (pred.ravel() >= 0.5).astype(int)

    def predict_proba(self, X):
        pred = self.model_.predict(X)
        return np.vstack([1 - pred.ravel(), pred.ravel()]).T

MODELS_PATH = "models"
os.makedirs(MODELS_PATH, exist_ok=True)

def download_model_from_drive(file_id, filename):
    url = f"https://drive.google.com/uc?id={file_id}"
    out_path = os.path.join(MODELS_PATH, filename)
    if not os.path.exists(out_path):
        gdown.download(url, out_path, quiet=False)
    return out_path

# –°–ª–æ–≤–Ω–∏–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
available_models = {
    "Random Forest": {
        "Mordred": {
            "–í—Å—ñ": "rf_pipeline_bundle_RF_ALL Mordred.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aliphatic_acyclic_Mordred.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aliphatic heteromono(poly)cyclic Mordred.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aromatic heteromono(poly)cyclic Mordred.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aromatic homomono(poly)cyclic Mordred.pkl"
        },
        "PaDEL": {
            "–í—Å—ñ": "rf_pipeline_bundle_RF_ALL PaDel.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aliphatic acyclic_PaDel.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aliphatic heteromono(poly)cyclic Class PaDel.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aromatic heteromono(poly) PaDel.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aromatic homomono(poly)cyclic Class PaDel.pkl"
        },
        "RDKit": {
            "–í—Å—ñ": "rf_pipeline_bundle_RF_ALL_RDkit.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aliphatic acyclic_RDkit.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aliphatic heteromono(poly)cyclic RDkit.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aromatic heteromono(poly)cyclic RDkit.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "rf_pipeline_bundle_Aromatic homomono(poly)cyclic RDkit.pkl"
        }
    },
    "Boosting": {
        "Mordred": {
            "–í—Å—ñ": "xgb_pipeline_bundle_ALL_Mordred.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aliphatic heteromono(poly)cyclic Class Mordred.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aliphatic heteromono(poly)cyclic Class Mordred.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aromatic heteromono(poly) cyclic Mordred.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aromatic homomono(poly)cyclic Mordred.pkl"
        },
        "PaDEL": {
            "–í—Å—ñ": "xgb_pipeline_bundle_ALL_PaDell.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aliphatic acyclic PaDelt.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aliphatic heteromono(poly)cyclic Class PaDel.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aromatic heteromono(poly) cyclic PaDelt.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aromatic homomono(poly)cyclic PaDelt.pkl"
        },
        "RDKit": {
            "–í—Å—ñ": "xgb_pipeline_bundle_ALL_RDkit.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aliphatic acyclic RDkit.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aliphatic heteromono(poly)cyclic RDkit.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aromatic heteromono(poly)cyclic RDkit.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "xgb_pipeline_bundle_Aromatic homomono(poly)cyclic RDkit.pkl" }
    },
    "Neural Network": {
        "Mordred": {
            "–í—Å—ñ": "nn_ALL_Mordred.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aliphatic acyclic Mordred.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aliphatic heteromono(poly)cyclic Class Mordred.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aromatic heteromono(poly)cyclic Class Mordred.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aromatic homomono(poly)cyclic Class Mordred.pkl"
        },
        "PaDEL": {
            "–í—Å—ñ": "nn_ALL PaDel.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aliphatic acyclic PaDel.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aliphatic heteromono(poly)cyclic PaDel.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aromatic heteromono(poly) cyclic Class PaDel.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aromatic homomono(poly)cyclic Class PaDel.pkl"
        },
        "RDKit": {
            "–í—Å—ñ": "nn_ALL_RDkit.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aliphatic acyclic RDkit.pkl",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aliphatic heteromono(poly)cyclic RDkit.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aromatic heteromono(poly)cyclic RDkit.pkl",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "nn_Aromatic homomono(poly)cyclic RDkit.pkl"
        }
    }
}

# –°–ª–æ–≤–Ω–∏–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
available_models2 = {
    "Random Forest": {
        "Mordred": {
            "–í—Å—ñ": "1pv4secP_mHC8f7eWeBt29k1VLnn7XJDe",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1wZXw5YwsFtd7nejxjde1f-aUgI2ymP_S",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "118X6QcqV6i-Q5fEoS7sMK4Ca2kcun9dd",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1aM4RUrVvJiSqDzdx7ROpFn-1dttjtNab",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1JKuOrpQU5t-0n2bLRmYZF7lHd-YNagzz"
        },
        "PaDEL": {
            "–í—Å—ñ": "1VVcD1jez6h1sfVIqyy_-Y985ZDPuaUYi",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1AnyrGIN8YHPM6vauaGQiDK4s4KooNoMV",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1OTk9EkMMkjjAjGR7DqntQ8yXfDlqbcmk",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1h8YgqtJ6H3P8ba7WHFgEsmooJ3uN4uzK",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "115cnVxY3NQah10ZNS50A18KHWbHEg5Qj"
        },
        "RDKit": {
            "–í—Å—ñ": "1OiFvjUKqblW4hom7mP-4FLGbbrOrjCy8",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1q_MkbGKWPzOGZ08BnVDW82TuTZFpAIUj",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1-cQEhRWDHyLHpDVVNgwQAttpAVg_dqFk",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "18RVgyCmbs27Y3LsG2u98VkwYLyA1XTDZ",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1jWK0IcVJmNLlhrLVRe4Cp1mgOtkHJcD5"
        }
    },
    "Boosting": {
        "Mordred": {
            "–í—Å—ñ": "1w2ItdAsDj033TGVRNTpqrHlR8a4SLhev",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1B5yeeidgex9srxieXKxkylag93Iy9iW0",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1W7cvJMf-s99NVAgYlFlto8b2jM4acNFI",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1I7QwKc0pPdgUY9UxeHkZOnBYto_buMkD",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1IbNUY3CzA9KitH6DmQeG76xCk2XeqP28"
        },
        "PaDEL": {
            "–í—Å—ñ": "1hc1houoqpU0vWtWf73VV9rXimZQBNJQ_",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1znSN_NQsxDBXBVZ5FQrzg6lMnVI56OAw",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1esmh0zAePZFUaOloWPo6c924W3BFKeGm",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1qwDQPQPHwwOr_33cAbcCd3BHPFvbEJ2q",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "15dH_u0NR87HGbDyO4Z_tQ7V2Uu4_Mpt2"
        },
        "RDKit": {
            "–í—Å—ñ": "1N41_t9myC9RNL7IFT2SVZtsyZn9LeGVt",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1w80izq8_jcopv-CpS4-TfYldMFVGaRwa",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1AUA51utgoZo8tGdIxJvIfizzShPJDlMk",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "12IFWcGkv73uZ4O1026bYVuWTla40v1vb",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "19DNaPEr5eB4UJV2lFx4MpIm23YdaVIwy" }
    },
    "Neural Network": {
        "Mordred": {
            "–í—Å—ñ": "1PXrEvA2nEcFi04Rvt0zuUX7QvOVGgo3W",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1D1DnRzQWGPXP-M-mam1zl_RCGRSzvoA5",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1GU6Y1gLrP6tfLtBC0TwAQ7v9VfQNpZuN",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1YnMs2d4IMFYvncvs-NxBCXQmjr7Glcc1",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1WIHJOUAYtvziM-us76csGTkB7qfgpM4a"
        },
        "PaDEL": {
            "–í—Å—ñ": "1lDRDFOGMhH3-Ev9TlefBDQb3ztJrezWr",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1_TpWE3J7ywXWx2Hh5Q_dgd348TB6tUSr",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "16PeB5VnL_cTc4gNu-5iJz3FCWbpE1xw3",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1LcDp2PDWcBbI-kvM5di7f4RrZF9HF0Ys",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "100Igu2pheFUz5Pd466RypXuoTcCDjCXl"
        },
        "RDKit": {
            "–í—Å—ñ": "1ZNTp1-mNxfjF0PbcwUqSo_q5NuXjPYlG",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1419IL9oUZbyNG7oaFYiSLYH27qL6y0GN",
            "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "17QDCWH7vAeXdoYoSvGKsNO3d4bb8rY1a",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1d1SUx2XeQWiPH9Fa5CLFOb61_m5fNELC",
            "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": "1GdcB1XGPIDRLoxoRSCCsmQ90NVMpumy3"
        }
    }
}

# –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ –ø—Ä–∞–≤–∏–ª–∞
auto_rules = {
    "–í—Å—ñ": ("Boosting", "Mordred"),
    "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ": ("Random Forest", "RDKit"),
    "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": ("Neural Network", "PaDEL"),
    "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": ("Random Forest", "RDKit"),
    "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ": ("Random Forest", "Mordred")
}


def load_model(model_type, descriptor, chem_class):
    # –ë–µ—Ä–µ–º–æ file_id —ñ–∑ available_models2
    file_id = available_models2[model_type][descriptor][chem_class]

    # –ë–µ—Ä–µ–º–æ —Ç–æ—á–Ω—É –Ω–∞–∑–≤—É —Ñ–∞–π–ª—É –∑ available_models
    filename = available_models[model_type][descriptor][chem_class]

    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ñ–∞–π–ª —ñ–∑ Google Drive, —è–∫—â–æ –≤—ñ–Ω —â–µ –Ω–µ —ñ—Å–Ω—É—î
    path = download_model_from_drive(file_id, filename)

    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –ø–∞–π–ø–ª–∞–π–Ω
    return joblib.load(path)

def make_prediction(df, pipeline_bundle, model_type):
    """–û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö —Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑"""

    if model_type in ["Random Forest", "Boosting"]:
        selector = pipeline_bundle.get("selector")
        scaler = pipeline_bundle.get("scaler")
        quantile_transformer = pipeline_bundle.get("quantile_transformer")
        all_features = pipeline_bundle["all_feature_names"]
        model = pipeline_bundle["model"]

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –≤—Å—ñ—Ö –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ñ–≤
        missing_cols = set(all_features) - set(df.columns)
        if missing_cols:
            st.error(f"‚ùå –£ —Ñ–∞–π–ª—ñ –Ω–µ –≤–∏—Å—Ç–∞—á–∞—î –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ñ–≤ –¥–ª—è –º–æ–¥–µ–ª—ñ: {missing_cols}")
            st.info("–°–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ—Å—è —Å–µ—Ä–≤—ñ—Å–∞–º–∏ –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ñ–≤")
            st.stop()

        X = df[all_features]
        X = X.replace([np.inf, -np.inf], 0).fillna(0)
        X = X.astype(np.float64)
        if quantile_transformer is not None:
            X = quantile_transformer.transform(X)
        if scaler is not None:
            X = scaler.transform(X)
        if selector is not None:
            X = selector.transform(X)
        preds = model.predict(X)

    elif model_type == "Neural Network":
        model = pipeline_bundle["model"]
        selected_features = pipeline_bundle["selected_feature_names"]
        missing_cols = set(selected_features) - set(df.columns)
        if missing_cols:
            st.error(f"‚ùå –£ —Ñ–∞–π–ª—ñ –Ω–µ –≤–∏—Å—Ç–∞—á–∞—î –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ñ–≤ –¥–ª—è –º–æ–¥–µ–ª—ñ: {missing_cols}")
            st.info("–°–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ—Å—è —Å–µ—Ä–≤—ñ—Å–∞–º–∏ –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ñ–≤")
            st.stop()
        X = df[selected_features]
        X = X.replace([np.inf, -np.inf], np.nan).fillna(0)
        X = np.float64(X.values)

        X = QuantileTransformer(output_distribution='uniform').fit_transform(X)
        X = StandardScaler().fit_transform(X)
        preds = model.predict(X)

    # –¥–æ–¥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    df_out = df.copy()
    labels = ["–†–∏–∑–∏–∫ –º—É—Ç–∞–≥–µ–Ω–Ω–æ—Å—Ç—ñ –≤–∏—Å–æ–∫–∏–π" if p >= 0.5 else "–†–∏–∑–∏–∫ –º—É—Ç–∞–≥–µ–Ω–Ω–æ—Å—Ç—ñ –Ω–∏–∑—å–∫–∏–π" for p in preds]
    df_out["Prediction"] = labels

    return df_out

# --- Streamlit UI ---
st.title("üß¨ AmesScan")
st.set_page_config( page_title="AmesScan", page_icon="üß¨", layout="wide")
st.markdown(
    """
    **–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –¥–ª—è –≤—Ö—ñ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª—É:**  
    - –§–∞–π–ª –º–∞—î –º—ñ—Å—Ç–∏—Ç–∏ —Å—Ç–æ–≤–ø–µ—Ü—å —ñ–∑ **SMILES-–Ω–æ—Ç–∞—Ü—ñ—è–º–∏ —Ö—ñ–º—ñ—á–Ω–∏—Ö —Å–ø–æ–ª—É–∫**, —è–∫–∏–π –º–æ–∂–µ –º–∞—Ç–∏ –æ–¥–Ω—É –∑ —Ç–∞–∫–∏—Ö –Ω–∞–∑–≤: SMILES, Canonical SMILES –∞–±–æ smiles.
    - –§–∞–π–ª –º–∞—î –º—ñ—Å—Ç–∏—Ç–∏ —Å—Ç–æ–≤–ø—Ü—ñ –∑ —á–∏—Å–ª–æ–≤–∏–º–∏ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω–∏–º–∏ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞–º–∏, –ø—Ä–∏—á–æ–º—É –ø–µ—Ä—à–∏–π —Ä—è–¥–æ–∫ –ø–æ–≤–∏–Ω–µ–Ω –≤–∏–∑–Ω–∞—á–∞—Ç–∏ –Ω–∞–∑–≤–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤.
    - –Ø–∫—â–æ —Ñ–∞–π–ª –º—ñ—Å—Ç–∏—Ç—å –ª–∏—à–µ SMILES-–Ω–æ—Ç–∞—Ü—ñ—ó, –º–æ–∂–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Ä–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ RDKit –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∏ –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑—É.  
    """
)
st.sidebar.header("–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")

descriptor_choice = st.sidebar.selectbox(
    "–û–±–µ—Ä—ñ—Ç—å –Ω–∞–±—ñ—Ä –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ñ–≤",
    ["–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ", "PaDEL", "RDKit", "Mordred"]
)

chem_class = st.sidebar.selectbox(
    "–û–±–µ—Ä—ñ—Ç—å –∫–ª–∞—Å",
    ["–í—Å—ñ", "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –∞—Ü–∏–∫–ª—ñ—á–Ω—ñ", "–ê–ª—ñ—Ñ–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ", "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–µ—Ç–µ—Ä–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ", "–ê—Ä–æ–º–∞—Ç–∏—á–Ω—ñ –≥–æ–º–æ—Ü–∏–∫–ª—ñ—á–Ω—ñ"]
)

if descriptor_choice == "–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ":
    # –≤–∏–∑–Ω–∞—á–∞—î–º–æ –º–æ–¥–µ–ª—å —ñ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∏ –∑ –ø—Ä–∞–≤–∏–ª
    model_type, descriptor_choice = auto_rules[chem_class]
    st.sidebar.info(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –≤–∏–±—ñ—Ä: {model_type} + {descriptor_choice}")
else:
    model_type = st.sidebar.selectbox("–û–±–µ—Ä—ñ—Ç—å –º–æ–¥–µ–ª—å", list(available_models.keys()))

st.sidebar.markdown("### üîó –†–µ—Å—É—Ä—Å–∏ –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ñ–≤:")
st.sidebar.markdown(
    """
    - [PaDEL](https://usegalaxy.eu/root?tool_id=padel&utm_source=chatgpt.com)
    - [Mordred](https://cheminformatics.usegalaxy.eu/root?tool_id=toolshed.g2.bx.psu.edu%2Frepos%2Fbgruening%2Fmordred%2Fctb_mordred_descriptors&utm_source=chatgpt.com)
    - [RDKit](https://usegalaxy.eu/root?tool_id=ctb_rdkit_descriptors&utm_source=chatgpt.com)
    """
)

uploaded_file = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª (.csv –∞–±–æ .xls)", type=["csv", "xls", "xlsx"])

if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
    except Exception as e:
        st.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ —Ñ–∞–π–ª: {e}")
        st.stop()

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–∏–π —Ñ–∞–π–ª
    if df.empty:
        st.warning("‚ö†Ô∏è –§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π. –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª –∑ –¥–∞–Ω–∏–º–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É.")
        st.stop()

    st.write("üìÇ –í—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ:")
    st.dataframe(df.head(), use_container_width=True)

    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —î –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∏
    if set(df.columns) <= {"SMILES", "Canonical SMILES", "smiles"}:
        st.warning("–ó–Ω–∞–π–¥–µ–Ω–æ –ª–∏—à–µ SMILES-–Ω–æ—Ç–∞—Ü—ñ—ó. –î–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É –ø–æ—Ç—Ä—ñ–±–Ω—ñ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∏.")

        if "computed_df" not in st.session_state:
            st.session_state.computed_df = None

        # --- –õ–æ–≥—ñ–∫–∞ –ø–æ–∫–∞–∑—É –∫–Ω–æ–ø–∫–∏ ---
        show_compute_button = False
        if descriptor_choice == "RDKit":
            show_compute_button = True
        elif descriptor_choice == "–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ" and auto_rules[chem_class][1] == "RDKit":
            show_compute_button = True

        if show_compute_button and st.button("–û–±—á–∏—Å–ª–∏—Ç–∏ RDKit –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ"):
            st.info("–û–±—á–∏—Å–ª–µ–Ω–Ω—è RDKit –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ñ–≤... –±—É–¥—å –ª–∞—Å–∫–∞, –∑–∞—á–µ–∫–∞–π—Ç–µ ‚è≥")

            # —Ç—É—Ç –π–¥–µ —Ç–≤—ñ–π –∫–æ–¥ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ñ–≤ RDKit
            rdkit_desc_names = [d[0] for d in Descriptors.descList]
            rdkit_data = []
            smiles_col = "SMILES" if "SMILES" in df.columns else "Canonical SMILES"
            invalid_smiles = []

            for i, smi in enumerate(df[smiles_col]):
                try:
                    mol = Chem.MolFromSmiles(smi)
                    if mol:
                        values = [desc[1](mol) for desc in Descriptors.descList]
                        rdkit_data.append(values)
                    else:
                        invalid_smiles.append(smi)
                        rdkit_data.append([None] * len(rdkit_desc_names))
                except:
                    invalid_smiles.append(smi)
                    rdkit_data.append([None] * len(rdkit_desc_names))

            rdkit_df = pd.DataFrame(rdkit_data, columns=rdkit_desc_names)
            df = pd.concat([df, rdkit_df], axis=1)
            st.session_state.computed_df = df

            if invalid_smiles:
                st.warning(f"‚ö†Ô∏è –î–ª—è {len(invalid_smiles)} –º–æ–ª–µ–∫—É–ª –Ω–µ –≤–¥–∞–ª–æ—Å—è –æ–±—á–∏—Å–ª–∏—Ç–∏ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∏.")

            st.success("‚úÖ RDKit –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∏ –æ–±—á–∏—Å–ª–µ–Ω–æ!")
            st.info("–¢–µ–ø–µ—Ä –≤–∏ –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑.")


        # –Ø–∫—â–æ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∏ –≤–∂–µ –æ–±—á–∏—Å–ª–µ–Ω—ñ ‚Äî –º–æ–∂–Ω–∞ –æ–¥—Ä–∞–∑—É –∑–∞–ø—É—Å–∫–∞—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑
        if st.session_state.computed_df is not None:
            df = st.session_state.computed_df

            if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑"):
                pipeline_bundle = load_model(model_type, descriptor_choice, chem_class)
                results = make_prediction(df, pipeline_bundle, model_type)

                st.success("‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ –≤–∏–∫–æ–Ω–∞–Ω–æ!")

                if "Canonical SMILES" in results.columns:
                    final_results = results[["Canonical SMILES", "Prediction"]]
                elif "SMILES" in results.columns:
                    final_results = results[["SMILES", "Prediction"]]
                else:
                    final_results = results[["Prediction"]]

                st.write("üìù –†–µ–∑—É–ª—å—Ç–∞—Ç–∏:")
                st.dataframe(final_results, use_container_width=True, height=400)

                output_file = "output.csv"
                final_results.to_csv(output_file, index=False)
                with open(output_file, "rb") as f:
                    st.download_button("‚¨áÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏", f, file_name="predictions.csv")

        else:
            st.info("""
                –î–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ñ–≤ –≤–∏ –º–æ–∂–µ—Ç–µ —Å–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏—Å—è —Å–µ—Ä–≤—ñ—Å–∞–º–∏:
                - [PaDEL](https://usegalaxy.eu/root?tool_id=padel&utm_source=chatgpt.com)
                - [Mordred](https://cheminformatics.usegalaxy.eu/root?tool_id=toolshed.g2.bx.psu.edu%2Frepos%2Fbgruening%2Fmordred%2Fctb_mordred_descriptors&utm_source=chatgpt.com)
                """)

    else:
        # –Ø–∫—â–æ —É —Ñ–∞–π–ª—ñ –≤–∂–µ —î –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∏
        st.success("‚úÖ –£ —Ñ–∞–π–ª—ñ –≤–∏—è–≤–ª–µ–Ω–æ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∏! –ú–æ–∂–Ω–∞ –æ–¥—Ä–∞–∑—É –≤–∏–∫–æ–Ω–∞—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑.")

        if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑"):
            pipeline_bundle = load_model(model_type, descriptor_choice, chem_class)
            results = make_prediction(df, pipeline_bundle, model_type)

            st.success("‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ –≤–∏–∫–æ–Ω–∞–Ω–æ!")

            if "Canonical SMILES" in results.columns:
                final_results = results[["Canonical SMILES", "Prediction"]]
            elif "SMILES" in results.columns:
                final_results = results[["SMILES", "Prediction"]]
            else:
                final_results = results[["Prediction"]]

            st.write("üìù –†–µ–∑—É–ª—å—Ç–∞—Ç–∏:")
            st.dataframe(final_results, use_container_width=True, height=400)

            output_file = "output.csv"
            final_results.to_csv(output_file, index=False)
            with open(output_file, "rb") as f:
                st.download_button("‚¨áÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏", f, file_name="predictions.csv")